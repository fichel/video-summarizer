{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2SkIvlVXDYaq",
        "outputId": "3469c861-dbc9-423b-a79a-673cef16503e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-wr4q039x\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-wr4q039x\n",
            "  Resolved https://github.com/openai/whisper.git to commit 248b6cb124225dd263bb9bd32d060b6517e067f8\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (2.0.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (0.56.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (2.0.1+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (4.65.0)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (9.1.0)\n",
            "Requirement already satisfied: tiktoken==0.3.3 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20230314) (0.3.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2022.10.31)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken==0.3.3->openai-whisper==20230314) (2.27.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.12.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->openai-whisper==20230314) (16.0.5)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230314) (0.39.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20230314) (67.7.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20230314) (3.1.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken==0.3.3->openai-whisper==20230314) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20230314) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20230314) (1.3.0)\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
            "Hit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
            "Hit:7 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
            "Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Hit:10 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Hit:11 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "21 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 21 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yNEqqc2dDzmH",
        "outputId": "52da6bda-b9d8-4ba7-e74a-861095841e73"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: whisper\n",
            "       [-h]\n",
            "       [--model {tiny.en,tiny,base.en,base,small.en,small,medium.en,medium,large-v1,large-v2,large}]\n",
            "       [--model_dir MODEL_DIR]\n",
            "       [--device DEVICE]\n",
            "       [--output_dir OUTPUT_DIR]\n",
            "       [--output_format {txt,vtt,srt,tsv,json,all}]\n",
            "       [--verbose VERBOSE]\n",
            "       [--task {transcribe,translate}]\n",
            "       [--language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}]\n",
            "       [--temperature TEMPERATURE]\n",
            "       [--best_of BEST_OF]\n",
            "       [--beam_size BEAM_SIZE]\n",
            "       [--patience PATIENCE]\n",
            "       [--length_penalty LENGTH_PENALTY]\n",
            "       [--suppress_tokens SUPPRESS_TOKENS]\n",
            "       [--initial_prompt INITIAL_PROMPT]\n",
            "       [--condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT]\n",
            "       [--fp16 FP16]\n",
            "       [--temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK]\n",
            "       [--compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD]\n",
            "       [--logprob_threshold LOGPROB_THRESHOLD]\n",
            "       [--no_speech_threshold NO_SPEECH_THRESHOLD]\n",
            "       [--word_timestamps WORD_TIMESTAMPS]\n",
            "       [--prepend_punctuations PREPEND_PUNCTUATIONS]\n",
            "       [--append_punctuations APPEND_PUNCTUATIONS]\n",
            "       [--highlight_words HIGHLIGHT_WORDS]\n",
            "       [--max_line_width MAX_LINE_WIDTH]\n",
            "       [--max_line_count MAX_LINE_COUNT]\n",
            "       [--threads THREADS]\n",
            "       audio\n",
            "       [audio ...]\n",
            "\n",
            "positional arguments:\n",
            "  audio\n",
            "    audio\n",
            "    file(s) to\n",
            "    transcribe\n",
            "\n",
            "options:\n",
            "  -h, --help\n",
            "    show this\n",
            "    help\n",
            "    message and\n",
            "    exit\n",
            "  --model {tiny.en,tiny,base.en,base,small.en,small,medium.en,medium,large-v1,large-v2,large}\n",
            "    name of the\n",
            "    Whisper\n",
            "    model to\n",
            "    use\n",
            "    (default:\n",
            "    small)\n",
            "  --model_dir MODEL_DIR\n",
            "    the path to\n",
            "    save model\n",
            "    files; uses\n",
            "    ~/.cache/wh\n",
            "    isper by\n",
            "    default\n",
            "    (default:\n",
            "    None)\n",
            "  --device DEVICE\n",
            "    device to\n",
            "    use for\n",
            "    PyTorch\n",
            "    inference\n",
            "    (default:\n",
            "    cuda)\n",
            "  --output_dir OUTPUT_DIR, -o OUTPUT_DIR\n",
            "    directory\n",
            "    to save the\n",
            "    outputs\n",
            "    (default:\n",
            "    .)\n",
            "  --output_format {txt,vtt,srt,tsv,json,all}, -f {txt,vtt,srt,tsv,json,all}\n",
            "    format of\n",
            "    the output\n",
            "    file; if\n",
            "    not\n",
            "    specified,\n",
            "    all\n",
            "    available\n",
            "    formats\n",
            "    will be\n",
            "    produced\n",
            "    (default:\n",
            "    all)\n",
            "  --verbose VERBOSE\n",
            "    whether to\n",
            "    print out\n",
            "    the\n",
            "    progress\n",
            "    and debug\n",
            "    messages\n",
            "    (default:\n",
            "    True)\n",
            "  --task {transcribe,translate}\n",
            "    whether to\n",
            "    perform\n",
            "    X->X speech\n",
            "    recognition\n",
            "    ('transcrib\n",
            "    e') or\n",
            "    X->English\n",
            "    translation\n",
            "    ('translate\n",
            "    ')\n",
            "    (default:\n",
            "    transcribe)\n",
            "  --language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}\n",
            "    language\n",
            "    spoken in\n",
            "    the audio,\n",
            "    specify\n",
            "    None to\n",
            "    perform\n",
            "    language\n",
            "    detection\n",
            "    (default:\n",
            "    None)\n",
            "  --temperature TEMPERATURE\n",
            "    temperature\n",
            "    to use for\n",
            "    sampling\n",
            "    (default:\n",
            "    0)\n",
            "  --best_of BEST_OF\n",
            "    number of\n",
            "    candidates\n",
            "    when\n",
            "    sampling\n",
            "    with non-\n",
            "    zero\n",
            "    temperature\n",
            "    (default:\n",
            "    5)\n",
            "  --beam_size BEAM_SIZE\n",
            "    number of\n",
            "    beams in\n",
            "    beam\n",
            "    search,\n",
            "    only\n",
            "    applicable\n",
            "    when\n",
            "    temperature\n",
            "    is zero\n",
            "    (default:\n",
            "    5)\n",
            "  --patience PATIENCE\n",
            "    optional\n",
            "    patience\n",
            "    value to\n",
            "    use in beam\n",
            "    decoding,\n",
            "    as in https\n",
            "    ://arxiv.or\n",
            "    g/abs/2204.\n",
            "    05424, the\n",
            "    default\n",
            "    (1.0) is\n",
            "    equivalent\n",
            "    to conventi\n",
            "    onal beam\n",
            "    search\n",
            "    (default:\n",
            "    None)\n",
            "  --length_penalty LENGTH_PENALTY\n",
            "    optional\n",
            "    token\n",
            "    length\n",
            "    penalty\n",
            "    coefficient\n",
            "    (alpha) as\n",
            "    in https://\n",
            "    arxiv.org/a\n",
            "    bs/1609.081\n",
            "    44, uses\n",
            "    simple\n",
            "    length norm\n",
            "    alization\n",
            "    by default\n",
            "    (default:\n",
            "    None)\n",
            "  --suppress_tokens SUPPRESS_TOKENS\n",
            "    comma-\n",
            "    separated\n",
            "    list of\n",
            "    token ids\n",
            "    to suppress\n",
            "    during\n",
            "    sampling;\n",
            "    '-1' will\n",
            "    suppress\n",
            "    most\n",
            "    special\n",
            "    characters\n",
            "    except\n",
            "    common punc\n",
            "    tuations\n",
            "    (default:\n",
            "    -1)\n",
            "  --initial_prompt INITIAL_PROMPT\n",
            "    optional\n",
            "    text to\n",
            "    provide as\n",
            "    a prompt\n",
            "    for the\n",
            "    first\n",
            "    window.\n",
            "    (default:\n",
            "    None)\n",
            "  --condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT\n",
            "    if True,\n",
            "    provide the\n",
            "    previous\n",
            "    output of\n",
            "    the model\n",
            "    as a prompt\n",
            "    for the\n",
            "    next\n",
            "    window;\n",
            "    disabling\n",
            "    may make\n",
            "    the text in\n",
            "    consistent\n",
            "    across\n",
            "    windows,\n",
            "    but the\n",
            "    model\n",
            "    becomes\n",
            "    less prone\n",
            "    to getting\n",
            "    stuck in a\n",
            "    failure\n",
            "    loop\n",
            "    (default:\n",
            "    True)\n",
            "  --fp16 FP16\n",
            "    whether to\n",
            "    perform\n",
            "    inference\n",
            "    in fp16;\n",
            "    True by\n",
            "    default\n",
            "    (default:\n",
            "    True)\n",
            "  --temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK\n",
            "    temperature\n",
            "    to increase\n",
            "    when\n",
            "    falling\n",
            "    back when\n",
            "    the\n",
            "    decoding\n",
            "    fails to\n",
            "    meet either\n",
            "    of the\n",
            "    thresholds\n",
            "    below\n",
            "    (default:\n",
            "    0.2)\n",
            "  --compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD\n",
            "    if the gzip\n",
            "    compression\n",
            "    ratio is\n",
            "    higher than\n",
            "    this value,\n",
            "    treat the\n",
            "    decoding as\n",
            "    failed\n",
            "    (default:\n",
            "    2.4)\n",
            "  --logprob_threshold LOGPROB_THRESHOLD\n",
            "    if the\n",
            "    average log\n",
            "    probability\n",
            "    is lower\n",
            "    than this\n",
            "    value,\n",
            "    treat the\n",
            "    decoding as\n",
            "    failed\n",
            "    (default:\n",
            "    -1.0)\n",
            "  --no_speech_threshold NO_SPEECH_THRESHOLD\n",
            "    if the\n",
            "    probability\n",
            "    of the <|no\n",
            "    speech|>\n",
            "    token is\n",
            "    higher than\n",
            "    this value\n",
            "    AND the\n",
            "    decoding\n",
            "    has failed\n",
            "    due to `log\n",
            "    prob_thresh\n",
            "    old`,\n",
            "    consider\n",
            "    the segment\n",
            "    as silence\n",
            "    (default:\n",
            "    0.6)\n",
            "  --word_timestamps WORD_TIMESTAMPS\n",
            "    (experiment\n",
            "    al) extract\n",
            "    word-level\n",
            "    timestamps\n",
            "    and refine\n",
            "    the results\n",
            "    based on\n",
            "    them\n",
            "    (default:\n",
            "    False)\n",
            "  --prepend_punctuations PREPEND_PUNCTUATIONS\n",
            "    if word_tim\n",
            "    estamps is\n",
            "    True, merge\n",
            "    these\n",
            "    punctuation\n",
            "    symbols\n",
            "    with the\n",
            "    next word\n",
            "    (default:\n",
            "    \"'“¿([{-)\n",
            "  --append_punctuations APPEND_PUNCTUATIONS\n",
            "    if word_tim\n",
            "    estamps is\n",
            "    True, merge\n",
            "    these\n",
            "    punctuation\n",
            "    symbols\n",
            "    with the\n",
            "    previous\n",
            "    word\n",
            "    (default: \"\n",
            "    '.。,，!！?？:：\n",
            "    ”)]}、)\n",
            "  --highlight_words HIGHLIGHT_WORDS\n",
            "    (requires -\n",
            "    -word_times\n",
            "    tamps True)\n",
            "    underline\n",
            "    each word\n",
            "    as it is\n",
            "    spoken in\n",
            "    srt and vtt\n",
            "    (default:\n",
            "    False)\n",
            "  --max_line_width MAX_LINE_WIDTH\n",
            "    (requires -\n",
            "    -word_times\n",
            "    tamps True)\n",
            "    the maximum\n",
            "    number of\n",
            "    characters\n",
            "    in a line\n",
            "    before\n",
            "    breaking\n",
            "    the line\n",
            "    (default:\n",
            "    None)\n",
            "  --max_line_count MAX_LINE_COUNT\n",
            "    (requires -\n",
            "    -word_times\n",
            "    tamps True)\n",
            "    the maximum\n",
            "    number of\n",
            "    lines in a\n",
            "    segment\n",
            "    (default:\n",
            "    None)\n",
            "  --threads THREADS\n",
            "    number of\n",
            "    threads\n",
            "    used by\n",
            "    torch for\n",
            "    CPU\n",
            "    inference;\n",
            "    supercedes \n",
            "    MKL_NUM_THR\n",
            "    EADS/OMP_NU\n",
            "    M_THREADS\n",
            "    (default:\n",
            "    0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper \"Novos produtos - Status 16_06.mp4\" --model medium --language br"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sChYzQ5NEGrv",
        "outputId": "7d1f949d-1929-446f-c29a-151cd258fc7e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████████████████████████████████| 1.42G/1.42G [00:10<00:00, 140MiB/s]\n",
            "[00:00.000 --> 00:08.000]  Olá pessoal, meu nome é Lucas, eu sou PM da Esquadra de Novos Produtos, hoje vou dar um update em relação às atividades até o dia 16, ok?\n",
            "[00:08.000 --> 00:16.000]  Bom, sobre as metas da empresa, um número que é muito positivo que temos aqui é em relação ao nosso forecast,\n",
            "[00:16.000 --> 00:25.000]  novamente, né, que estamos aqui com boas expectativas de superar aos números do mês de junho de 2023, tá?\n",
            "[00:25.000 --> 00:30.000]  Outra informação aqui das nossas metas que não é algo tão positivo, tá?\n",
            "[00:30.000 --> 00:35.000]  Mas em relação aos nossos produtos aqui de property, RCRD, tá?\n",
            "[00:35.000 --> 00:47.000]  É que existe aqui uma diferença de números, né, do que realmente a gente estaria planejado por aquilo que realizamos ou estamos com expectativas de realizar, tá?\n",
            "[00:48.000 --> 01:03.000]  Nos próximos dias eu pretendo conversar já com a Maiara e também com o Fernando pra conversar pra ver como podemos ajudar, né, a tirar essa diferença desses números, ok?\n",
            "[01:04.000 --> 01:12.000]  A gente sabe que existe já algumas integrações, algumas parceiras firmadas que antigamente tínhamos altas expectativas,\n",
            "[01:12.000 --> 01:20.000]  agora parece aparentemente não está rolando tão bem as vendas, né, por exemplo a BizBank, eu lembro que no começo a gente tinha altas expectativas,\n",
            "[01:20.000 --> 01:31.000]  eu gostaria de saber conversando com eles pra entender como podemos ajudar, né, porque a gente sabe que demora bastante tempo pra gente conseguir realmente fazer uma parceria,\n",
            "[01:31.000 --> 01:51.000]  se não uma parceria, fazer toda essa integração tecnológica entre as empresas e como a gente já tá lá dentro, né, eu acho que vale a pena a gente, se for, se possível, né, a gente colocar uma energia a mais pra ver, fazer realmente acontecer essas vendas, tá, dentro dessa, dos nossos parceiros, tá bom?\n",
            "[01:52.000 --> 02:07.000]  Bom, agora falando um pouco das atividades aqui da Squad, semana passada a gente não conseguiu realizar ainda a correção, né, é uma correção que tá com o time da Ebal, eles não conseguiram,\n",
            "[02:07.000 --> 02:19.000]  provavelmente eles vão terminar essa semana, então a hora que eles realmente finalizarem a gente faz as emissões faltantes aqui do nosso produto do primeiro tombamento, tá bom?\n",
            "[02:19.000 --> 02:47.000]  Agora falando do nosso terceiro item, já configuramos aqui esses dois novos produtos, o AV2 e o B, ok, dentro da plataforma SureMall, vamos começar já a homologação aqui batimento de prêmio e estamos já homologando todas aquelas etapas onde passa do SureMall pro AirHub, pro V3 e pros sistemas adjacentes, tá, então aqui tá de uma visão super maca da atividade,\n",
            "[02:47.000 --> 03:16.000]  né, porque ela se ramifica em várias atividades objetivos bem menores, mas são várias etapas, ok, e por último aqui do produto D ainda não temos a especificação dela, né, mas foi bem alinhado junto com o nosso subscritor, né, o Carlão, de que pra utilizarmos o mesmo, né, o mesmo formato que utilizamos aqui pro nosso produto B, AV2, pra simplificarmos a configuração dele dentro do SureMall.\n",
            "[03:17.000 --> 03:39.000]  Tá, então até mesmo para os novos parceiros, etc, a gente sempre pensar no mesmo mold, né, então LMI vezes taxa, né, talvez fechando sempre em planos, então isso facilita bastante porque a gente já tem um esqueleto já pré-definido lá dentro e isso facilita muito a configuração e agiliza o processo de integração e desenvolvimento junto ao nosso parceiro, tá bom?\n",
            "[03:39.000 --> 04:07.000]  Então aqui, mudando um pouco de assunto, gostaria de colocar alguns números, né, em relação ao nosso, quais são as expectativas em relação ao produto B e o AV2, tá, conversando lá com o pessoal da Stone, expectativa é que as planilhas desses produtos somem em torno de 700 certificados, tá, desse tombamento de junho pra esses dois produtos, tá, pegando uma média aqui de valor de 647,000, tá bom?\n",
            "[04:09.000 --> 04:31.000]  Então esse número de 50 foi a média do nosso, do valor do primeiro tombamento, tá, então pode ser que seja diferente, mas é o número que a gente tem pra tomar como base, tá, tendo em vista esses números a gente estaria estimando o valor de 453 mil reais pro, pra esse tombamento do mês de junho, tá bom?\n",
            "[04:31.000 --> 04:52.000]  Só desses dois produtos, do B e o AV2, tá, lembrando que esses tombamentos eles vão ser corriqueiros, então mês a mês vamos ter novos tombamentos, dessa vez pode ser em torno de 700, né, mas até o fim do ano, se não me falem a memória, é em torno de 30 mil, tá bom?\n",
            "[04:53.000 --> 05:15.000]  Bom, agora falando sobre nosso produto C, tá, então falar alguns números que temos até o momento, então foram 11 dias úteis de operação, tá, nesse mês de junho, até então já vendemos 800 certificados novos, tá, combatendo um prêmio de mais de um milhão nesses 11 dias de operação, tá bom?\n",
            "[05:15.000 --> 05:42.000]  Gostaria agora de apresentar pra vocês o que temos aprendido com essas vendas do produto C, né, então como que é o comportamento dessas vendas, né, então até agora do começo do mês com aquelas, com as vendas, né, então o valor médio de cada contratação é de 1.333 reais,\n",
            "[05:42.000 --> 06:12.000]  quantidade média que temos aqui de vendas por dia é de 73 reais, tá, e o total de prêmio diário é de 97.309, tá, se a gente seguir na mesma linha de vendas até o nosso fim do mês, onde temos mais 10 dias úteis, a gente chegaria aqui na casa de quase 1 milhão de reais, né, então aqui chegando na verdade de 973 mil e 90 mil reais, tá, claro que isso aqui a gente ainda não tem, né, a gente ainda não tem\n",
            "[06:12.000 --> 06:33.000]  é uma expectativa, tá, é o que a gente tá na nossa visão se tudo ele continuar na mesma linha de média que a gente viu nesses primeiros 11 dias de vendas, tá, então a gente vai ver o comportamento, tirar uma lição, né, pra gente já ter uma maior previsibilidade pros próximos meses, tá bom?\n",
            "[06:33.000 --> 06:44.000]  bom é isso pessoal é qualquer dúvida por favor entre em contato deixa uma mensagem aqui no vídeo que iremos responder boa tarde tchau tchau\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper \"Evolução Cyber e E&O - 16-06.mp4\" --model medium --language br --output_format txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bewcVqpwFGj5",
        "outputId": "71fa1361-f4e6-4a75-c379-79960ef29402"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:00.000 --> 00:07.000]  Oi pessoal, vou passar para vocês os updates da nossa squad de Genui Cyber aqui para a metade do mês de junho.\n",
            "[00:07.000 --> 00:17.000]  Neste mês recebemos aí alguns reforços, então temos aqui a nossa equipe, o Nidson de Kiá, a Sabrina de Front End.\n",
            "[00:17.000 --> 00:22.000]  Chegou a Rubia, mais nova a Front End, seja bem-vinda.\n",
            "[00:22.000 --> 00:29.000]  Chegamos aqui também com o novo reforço em Back End, o Marcelo Paiva, para trabalhar com o Evandro e o Rodrigo também.\n",
            "[00:29.000 --> 00:35.000]  E esse é o nosso time, a nossa gangue para fazer acontecer tudo que a gente precisa para este ano.\n",
            "[00:35.000 --> 00:43.000]  Aqui eu trouxe o status das nossas metas até maio. A gente fez um trabalho de apuração dessas metas.\n",
            "[00:43.000 --> 00:54.000]  Eu queria trazer para vocês o que a gente evoluiu e o que a gente vai ter que trazer um pouco mais de esforço ali para os próximos meses.\n",
            "[00:54.000 --> 01:08.000]  Falando de GWP contábil, a gente está aqui 6 pontos percentuais acima do que a gente esperava até maio, então parabéns para o time.\n",
            "[01:08.000 --> 01:17.000]  E o GW margem aqui, que é a margem de subscripção ainda, está sendo avaliada pelo time dublatorial, Richard.\n",
            "[01:17.000 --> 01:21.000]  Então, assim que a gente tiver um update, eu trago para vocês.\n",
            "[01:21.000 --> 01:35.000]  Bem como o GWP no digital, a gente está praticamente em linha, nosso objetivo era 44 milhões, a gente está com 43.5, 3 pontos percentuais, mas com certeza a gente vai mitigar aí ao longo dos meses.\n",
            "[01:35.000 --> 01:54.000]  Para corretores ativos, essa é a meta com mais ofensor hoje. A gente tinha uma expectativa de chegar em maio em 5.300, 5.300 e a gente está com 4.287, corresponde a uma queda de 19 pontos percentuais.\n",
            "[01:54.000 --> 02:06.000]  Mas o time de subscripção tem uma agenda bem parruda e completa de acompanhamento e resgate desses corretores que deixaram de produzir com Yenon, principalmente.\n",
            "[02:06.000 --> 02:15.000]  Nosso reach ratio também está bem interessante, a gente tem feito aí 30%, que é acima da meta até a meta 13.\n",
            "[02:15.000 --> 02:25.000]  Então a gente está ultrapassando a nossa meta e a perspectiva é que a gente fique com esse resultado positivo ao longo dos meses.\n",
            "[02:25.000 --> 02:31.000]  E renovação a gente está praticamente flat aqui, com 82% de renovação, isso é muito bom.\n",
            "[02:31.000 --> 02:41.000]  A gente tem se dedicado dentro do time de tecnologia para mitigar as causas raízes dos problemas de renovação e a perspectiva é que isso só melhore ao longo dos meses também.\n",
            "[02:41.000 --> 02:53.000]  Falando agora do nosso resultado, como companhia a gente tem um forecast otimista com 94 milhões, que corresponde a uma superação de 120% do nosso plano.\n",
            "[02:54.000 --> 03:06.000]  Isso ajuda a gente a chegar mais perto do nosso plano acumulado, que hoje ficaria aqui com 94%, então a gente está chegando perto do nosso objetivo.\n",
            "[03:06.000 --> 03:15.000]  E vamos chegar aí no um bilhão, que é a nossa meta superior, nossa meta do final do ano.\n",
            "[03:15.000 --> 03:25.000]  Falando para Yanow e Cyber, a gente tem uma perspectiva aqui para o mês de junho positiva, porque o mês de junho é super estratégico para o volume de renovações que a gente tem.\n",
            "[03:25.000 --> 03:37.000]  E a ideia é que a gente chegue também mais perto do nosso plano de 11 milhões, nosso forecast está apontando 9.2 aqui e a gente fez 3.5 por hora.\n",
            "[03:37.000 --> 03:52.000]  Agora dando zoom em Cyber, a gente tem um resultado aqui negativo, mas não se assustem, é porque a gente teve um cancelamento no começo desse mês, mas o bom é que a gente já fez uma venda neste mês para mitigar isso.\n",
            "[03:52.000 --> 04:07.000]  Então a gente fez uma venda de 57 mil reais e a gente ainda está com esse gap de mil reais aqui em Cyber, mas até o final do mês com certeza a gente vai superar esse momento de baixa.\n",
            "[04:07.000 --> 04:27.000]  Falando agora das nossas iniciativas dentro da Esquad para Yanow, a gente tem como objetivo nesse sprint agora finalizar a mitigação das causas raiz dos problemas que a gente já conhece com a renovação e começar a dar mais tração para as inovações que a gente precisa para Yanow.\n",
            "[04:27.000 --> 04:48.000]  O que a gente já está desenvolvendo? O ajuste na modalidade de engenheiros e arquitetos, a gente já evoluiu bastante nessa semana com esse desenvolvimento e a perspectiva é super otimista para a gente entregar isso mais rápido possível e fazer barulho junto com o time de marketing, fazer um plano para a gente contar essa novidade para a nossa base.\n",
            "[04:48.000 --> 05:16.000]  Quais são as entregas que a gente tem planjadas para o começo dessa semana? A gente vai terminar essa parte de cancelamento manual que não retroalimenta dentro das nossas tabelas hoje, o que a gente cancela no e-ball hoje não tem esse reflexo automático dentro das nossas tabelas, a gente vai terminar, e multiprofessionais também que a gente deu uma paralisada para a gente focar nesses problemas de renovação, mas a ideia é já entregar no começo da semana.\n",
            "[05:18.000 --> 05:47.000]  Como próximos desenvolvimentos, o que tem aqui no nosso pipeline? A atualização dos honorários advocatícios, a gente também deu uma acelerada no refinamento desse item nessa semana, a ideia é que a gente comece o front e nessa próxima semana já junto com o time de back para a gente entregar também isso mais rápido possível, a perspectiva é que a gente comece a desenvolver e termina ali no meado de julho.\n",
            "[05:49.000 --> 06:09.000]  Bem como a inclusão do campo de alvará para o RCPE, isso foi uma solicitação para uma parceria e a gente vai disponibilizar também isso via API para que nossas parcerias consigam consumir essa informação.\n",
            "[06:10.000 --> 06:32.000]  Além disso, a gente hoje não tem dentro do nosso formulário o valor do sinistro, então quando chega uma nova cotação a gente não pergunta o valor, apenas a quantidade de sinistros e isso a gente perde uma oportunidade de agravar esse possível segurado e esse prêmio.\n",
            "[06:32.000 --> 06:44.000]  Então por isso que a gente vai colocar isso também está no nosso pipeline, bem como a migração de clínica multidisciplinares para o Enchermon, que também a gente quer começar a fazer o quanto antes.\n",
            "[06:45.000 --> 07:06.000]  Aqui eu só queria dar também um outro overview que desdobrou desse trabalho que a gente está fazendo de causas raízes dentro da escuad, a gente fez um trabalho minucioso de olhar o porquê que as datas não estavam batendo das renovações e a gente acabou achando também que a policies estavam com as datas erradas.\n",
            "[07:06.000 --> 07:34.000]  E aí foi um trabalho muito em conjunto com várias áreas, então eu trouxe aqui muito para agradecer todas as áreas, foi um trabalho em equipe e acho que é um grande exemplo de que quando a gente tem um time multifuncional que quer trazer um novo serviço, um atendimento diferenciado para o nosso corretor, quando a gente se junta a gente faz coisas maiores e realmente junto a gente é mais forte.\n",
            "[07:34.000 --> 07:53.000]  Então o que aconteceu aqui, a gente teve 320 casos que estavam com as datas erradas, o time de tecnologia, a minha escuad junto com a escuad da Kelly realizam um ajuste dessa causa raiz em maio, só que a gente tinha um trabalho de corrigir esse legado.\n",
            "[07:53.000 --> 08:22.000]  Então o time de operações realizou todo o processo de cancelamento e remissão, então agradeço demais o time de operações, o time de finanças deu baixa nessas comissões, o time de tecnologia na sexta-feira atualizou o status, o Guilherme fez esse suporte com a gente também e a gente alinhou um plano de comunicação com o marketing que vai fazer esse disparo na segunda-feira para esses corretores impactados.\n",
            "[08:22.000 --> 08:43.000]  Aqui tem a lista dos produtos impactados, como vocês podem ver a maior parte realmente é ENO, mas eu queria muito agradecer novamente esse trabalho em conjunto que a gente fez em prol de um serviço diferenciado e com foco realmente na causa raiz.\n",
            "[08:43.000 --> 08:56.000]  Então é isso gente, queria muito agradecer todo mundo e caso tenham alguma outra sugestão, feedback, eu estou sempre a uma mensagem de distância. Obrigada.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3gaSRPLZ_iyE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}